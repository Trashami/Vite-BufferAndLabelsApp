import {
  c as c2,
  f as f2,
  i
} from "./chunk-PNLWREZJ.js";
import {
  c,
  d,
  v
} from "./chunk-7QNA4ADD.js";
import {
  e
} from "./chunk-C6PUUIY2.js";
import {
  a
} from "./chunk-TGHV3HKU.js";
import {
  e as e2,
  f
} from "./chunk-BQL7VXQR.js";
import {
  o
} from "./chunk-735C75BI.js";
import {
  n
} from "./chunk-ZLTZ3KAT.js";
import {
  O
} from "./chunk-RUM3DXFX.js";

// node_modules/@arcgis/core/views/3d/webgl-engine/core/shaderLibrary/hud/HUDUniforms.js
var c3;
!function(c5) {
  c5[c5.Occluded = 0] = "Occluded", c5[c5.NotOccluded = 1] = "NotOccluded", c5[c5.Both = 2] = "Both", c5[c5.COUNT = 3] = "COUNT";
}(c3 || (c3 = {}));

// node_modules/@arcgis/core/views/3d/webgl-engine/core/shaderLibrary/hud/HUD.glsl.js
var p;
function u(u2, v2) {
  u2.include(c2), u2.attributes.add(O.POSITION, "vec3"), u2.attributes.add(O.NORMAL, "vec3"), u2.attributes.add(O.AUXPOS1, "vec4");
  const m = u2.vertex;
  v(m, v2), c(m, v2), m.uniforms.add([new e("viewport", (e3, t) => t.camera.fullViewport), new o("polygonOffset", (e3) => e3.shaderPolygonOffset), new o("cameraGroundRelative", (e3, t) => t.camera.aboveGround ? 1 : -1), new o("renderTransparentlyOccludedHUD", (e3, o2) => o2.renderTransparentlyOccludedHUD === c3.Occluded ? 1 : o2.renderTransparentlyOccludedHUD === c3.NotOccluded ? 0 : 0.75), new f("hudVisibilityTexture", (e3, t) => t.hudVisibilityTexture)]), v2.hasVerticalOffset && f2(m), m.constants.add("smallOffsetAngle", "float", 0.984807753012208), m.code.add(n`struct ProjectHUDAux {
vec3 posModel;
vec3 posView;
vec3 vnormal;
float distanceToCamera;
float absCosAngle;
};`), m.code.add(n`float applyHUDViewDependentPolygonOffset(float pointGroundDistance, float absCosAngle, inout vec3 posView) {
float pointGroundSign = sign(pointGroundDistance);
if (pointGroundSign == 0.0) {
pointGroundSign = cameraGroundRelative;
}
float groundRelative = cameraGroundRelative * pointGroundSign;
if (polygonOffset > .0) {
float cosAlpha = clamp(absCosAngle, 0.01, 1.0);
float tanAlpha = sqrt(1.0 - cosAlpha * cosAlpha) / cosAlpha;
float factor = (1.0 - tanAlpha / viewport[2]);
if (groundRelative > 0.0) {
posView *= factor;
}
else {
posView /= factor;
}
}
return groundRelative;
}`), v2.isDraped && !v2.hasVerticalOffset || d(m), v2.isDraped || (m.uniforms.add(new o("perDistancePixelRatio", (e3, t) => Math.tan(t.camera.fovY / 2) / (t.camera.fullViewport[2] / 2))), m.code.add(n`void applyHUDVerticalGroundOffset(vec3 normalModel, inout vec3 posModel, inout vec3 posView) {
float distanceToCamera = length(posView);
float pixelOffset = distanceToCamera * perDistancePixelRatio * 0.5;
vec3 modelOffset = normalModel * cameraGroundRelative * pixelOffset;
vec3 viewOffset = (viewNormal * vec4(modelOffset, 1.0)).xyz;
posModel += modelOffset;
posView += viewOffset;
}`)), v2.screenCenterOffsetUnitsEnabled === p.Screen && m.uniforms.add(new o("pixelRatio", (e3, t) => t.camera.pixelRatio)), v2.hasScreenSizePerspective && i(m), m.code.add(n`
    vec4 projectPositionHUD(out ProjectHUDAux aux) {
      // centerOffset is in view space and is used to implement world size offsetting
      // of labels with respect to objects. It also pulls the label towards the viewer
      // so that the label is visible in front of the object.
      vec3 centerOffset = auxpos1.xyz;

      // The pointGroundDistance is the distance of the geometry to the ground and is
      // negative if the point is below the ground, or positive if the point is above
      // ground.
      float pointGroundDistance = auxpos1.w;

      aux.posModel = position;
      aux.posView = (view * vec4(aux.posModel, 1.0)).xyz;
      aux.vnormal = normal;
      ${v2.isDraped ? "" : "applyHUDVerticalGroundOffset(aux.vnormal, aux.posModel, aux.posView);"}

      // Screen sized offset in world space, used for example for line callouts
      // Note: keep this implementation in sync with the CPU implementation, see
      //   - MaterialUtil.verticalOffsetAtDistance
      //   - HUDMaterial.applyVerticalOffsetTransformation

      aux.distanceToCamera = length(aux.posView);

      vec3 viewDirObjSpace = normalize(cameraPosition - aux.posModel);
      float cosAngle = dot(aux.vnormal, viewDirObjSpace);

      aux.absCosAngle = abs(cosAngle);

      ${v2.hasScreenSizePerspective && (v2.hasVerticalOffset || v2.screenCenterOffsetUnitsEnabled === p.Screen) ? "vec4 perspectiveFactor = screenSizePerspectiveScaleFactor(aux.absCosAngle, aux.distanceToCamera, screenSizePerspectiveAlignment);" : ""}

      ${v2.hasVerticalOffset ? v2.hasScreenSizePerspective ? "float verticalOffsetScreenHeight = applyScreenSizePerspectiveScaleFactorFloat(verticalOffset.x, perspectiveFactor);" : "float verticalOffsetScreenHeight = verticalOffset.x;" : ""}

      ${v2.hasVerticalOffset ? n`
            float worldOffset = clamp(verticalOffsetScreenHeight * verticalOffset.y * aux.distanceToCamera, verticalOffset.z, verticalOffset.w);
            vec3 modelOffset = aux.vnormal * worldOffset;
            aux.posModel += modelOffset;
            vec3 viewOffset = (viewNormal * vec4(modelOffset, 1.0)).xyz;
            aux.posView += viewOffset;
            // Since we elevate the object, we need to take that into account
            // in the distance to ground
            pointGroundDistance += worldOffset;` : ""}

      float groundRelative = applyHUDViewDependentPolygonOffset(pointGroundDistance, aux.absCosAngle, aux.posView);

      ${v2.screenCenterOffsetUnitsEnabled !== p.Screen ? n`
            // Apply x/y in view space, but z in screen space (i.e. along posView direction)
            aux.posView += vec3(centerOffset.x, centerOffset.y, 0.0);

            // Same material all have same z != 0.0 condition so should not lead to
            // branch fragmentation and will save a normalization if it's not needed
            if (centerOffset.z != 0.0) {
              aux.posView -= normalize(aux.posView) * centerOffset.z;
            }
          ` : ""}

      vec4 posProj = proj * vec4(aux.posView, 1.0);

      ${v2.screenCenterOffsetUnitsEnabled === p.Screen ? v2.hasScreenSizePerspective ? "float centerOffsetY = applyScreenSizePerspectiveScaleFactorFloat(centerOffset.y, perspectiveFactor);" : "float centerOffsetY = centerOffset.y;" : ""}

      ${v2.screenCenterOffsetUnitsEnabled === p.Screen ? "posProj.xy += vec2(centerOffset.x, centerOffsetY) * pixelRatio * 2.0 / viewport.zw * posProj.w;" : ""}

      // constant part of polygon offset emulation
      posProj.z -= groundRelative * polygonOffset * posProj.w;
      return posProj;
    }
  `), m.code.add(n`bool testVisibilityHUD(vec4 posProj) {
vec4 posProjCenter = alignToPixelCenter(posProj, viewport.zw);
vec4 occlusionPixel = texture2D(hudVisibilityTexture, .5 + .5 * posProjCenter.xy / posProjCenter.w);
if (renderTransparentlyOccludedHUD > 0.5) {
return occlusionPixel.r * occlusionPixel.g > 0.0 && occlusionPixel.g * renderTransparentlyOccludedHUD < 1.0;
}
return occlusionPixel.r * occlusionPixel.g > 0.0 && occlusionPixel.g == 1.0;
}`);
}
!function(e3) {
  e3[e3.World = 0] = "World", e3[e3.Screen = 1] = "Screen", e3[e3.COUNT = 2] = "COUNT";
}(p || (p = {}));

// node_modules/@arcgis/core/views/3d/webgl-engine/core/shaderLibrary/hud/AlignPixel.glsl.js
function c4(c5) {
  const i2 = n`vec4 alignToPixelCenter(vec4 clipCoord, vec2 widthHeight) {
vec2 xy = vec2(0.500123) + 0.5 * clipCoord.xy / clipCoord.w;
vec2 pixelSz = vec2(1.0) / widthHeight;
vec2 ij = (floor(xy * widthHeight) + vec2(0.5)) * pixelSz;
vec2 result = (ij * 2.0 - vec2(1.0)) * clipCoord.w;
return vec4(result, clipCoord.zw);
}`, o2 = n`vec4 alignToPixelOrigin(vec4 clipCoord, vec2 widthHeight) {
vec2 xy = vec2(0.5) + 0.5 * clipCoord.xy / clipCoord.w;
vec2 pixelSz = vec2(1.0) / widthHeight;
vec2 ij = floor((xy + 0.5 * pixelSz) * widthHeight) * pixelSz;
vec2 result = (ij * 2.0 - vec2(1.0)) * clipCoord.w;
return vec4(result, clipCoord.zw);
}`;
  c5.vertex.code.add(i2), c5.vertex.code.add(o2), c5.fragment.code.add(i2), c5.fragment.code.add(o2);
}

// node_modules/@arcgis/core/views/3d/webgl-engine/core/shaderLibrary/shading/MultipassGeometryTest.glsl.js
function a2(a3) {
  a3.include(a), a3.uniforms.add([new f("geometryDepthTexture", (e3, r) => r.multipassGeometry.linearDepthTexture), new e2("nearFar", (e3, r) => r.camera.nearFar)]), a3.code.add(n`bool geometryDepthTest(vec2 pos, float elementDepth) {
float geometryDepth = linearDepthFromTexture(geometryDepthTexture, pos, nearFar);
return (elementDepth < (geometryDepth - 1.0));
}`);
}
var s = class {
  constructor() {
    this.enabled = false;
  }
};

export {
  p,
  u,
  c4 as c,
  a2 as a,
  s
};
//# sourceMappingURL=chunk-TMILTRNC.js.map
