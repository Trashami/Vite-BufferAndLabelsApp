import {
  i as i2
} from "./chunk-5OCLJKTT.js";
import {
  e as e3,
  r as r2,
  u as u2
} from "./chunk-HNRPDSCT.js";
import {
  t as t2
} from "./chunk-XTFH7327.js";
import {
  c as c3
} from "./chunk-D2XA6Z6P.js";
import {
  _,
  n as n4,
  x
} from "./chunk-O4DPVR3F.js";
import {
  E as E2,
  n as n3
} from "./chunk-MATM5L52.js";
import {
  D,
  E,
  G,
  L,
  M,
  P,
  V as V2,
  Y,
  u
} from "./chunk-3OFVLRSL.js";
import {
  e as e2
} from "./chunk-EGV5SNBD.js";
import {
  n as n2
} from "./chunk-O6VYMEIX.js";
import {
  a as a2
} from "./chunk-ZPYDYUP5.js";
import {
  c,
  i
} from "./chunk-C5H57NTD.js";
import {
  n
} from "./chunk-THVR7IAM.js";
import {
  c as c2
} from "./chunk-DMI7A7TC.js";
import {
  V,
  X
} from "./chunk-KAN4HXCG.js";
import {
  a,
  f as f2,
  v
} from "./chunk-MJXQTGI2.js";
import {
  s as s2
} from "./chunk-LIZHLHNA.js";
import {
  s2 as s
} from "./chunk-UA3YPL2R.js";
import {
  e,
  o
} from "./chunk-6QC7MLLS.js";
import {
  f,
  h,
  r,
  t
} from "./chunk-MIHB3CIK.js";

// node_modules/@arcgis/core/libs/basisu/BasisU.js
function s3() {
  if (t(i3)) {
    const t3 = (t4) => a2(`esri/libs/basisu/${t4}`);
    i3 = import("./basis_transcoder-DG2W3LZZ.js").then((e4) => e4.b).then(({ default: e4 }) => e4({ locateFile: t3 }).then((e5) => (e5.initializeBasis(), delete e5.then, e5)));
  }
  return i3;
}
var i3;

// node_modules/@arcgis/core/libs/basisu/TextureFormat.js
var _2;
!function(_5) {
  _5[_5.ETC1_RGB = 0] = "ETC1_RGB", _5[_5.ETC2_RGBA = 1] = "ETC2_RGBA", _5[_5.BC1_RGB = 2] = "BC1_RGB", _5[_5.BC3_RGBA = 3] = "BC3_RGBA", _5[_5.BC4_R = 4] = "BC4_R", _5[_5.BC5_RG = 5] = "BC5_RG", _5[_5.BC7_M6_RGB = 6] = "BC7_M6_RGB", _5[_5.BC7_M5_RGBA = 7] = "BC7_M5_RGBA", _5[_5.PVRTC1_4_RGB = 8] = "PVRTC1_4_RGB", _5[_5.PVRTC1_4_RGBA = 9] = "PVRTC1_4_RGBA", _5[_5.ASTC_4x4_RGBA = 10] = "ASTC_4x4_RGBA", _5[_5.ATC_RGB = 11] = "ATC_RGB", _5[_5.ATC_RGBA = 12] = "ATC_RGBA", _5[_5.FXT1_RGB = 17] = "FXT1_RGB", _5[_5.PVRTC2_4_RGB = 18] = "PVRTC2_4_RGB", _5[_5.PVRTC2_4_RGBA = 19] = "PVRTC2_4_RGBA", _5[_5.ETC2_EAC_R11 = 20] = "ETC2_EAC_R11", _5[_5.ETC2_EAC_RG11 = 21] = "ETC2_EAC_RG11", _5[_5.RGBA32 = 13] = "RGBA32", _5[_5.RGB565 = 14] = "RGB565", _5[_5.BGR565 = 15] = "BGR565", _5[_5.RGBA4444 = 16] = "RGBA4444";
}(_2 || (_2 = {}));

// node_modules/@arcgis/core/views/3d/webgl-engine/lib/BasisUtil.js
var g = null;
var l = null;
async function c4() {
  return t(l) && (l = s3(), g = await l), l;
}
function u3(t3, n5) {
  if (t(g))
    return t3.byteLength;
  const r3 = new g.BasisFile(new Uint8Array(t3)), s5 = T(r3) ? E3(r3.getNumLevels(0), r3.getHasAlpha(), r3.getImageWidth(0, 0), r3.getImageHeight(0, 0), n5) : 0;
  return r3.close(), r3.delete(), s5;
}
function m(t3, n5) {
  if (t(g))
    return t3.byteLength;
  const r3 = new g.KTX2File(new Uint8Array(t3)), s5 = _3(r3) ? E3(r3.getLevels(), r3.getHasAlpha(), r3.getWidth(), r3.getHeight(), n5) : 0;
  return r3.close(), r3.delete(), s5;
}
function E3(e4, t3, n5, s5, i5) {
  const a3 = _(t3 ? u.COMPRESSED_RGBA8_ETC2_EAC : u.COMPRESSED_RGB8_ETC2), g3 = i5 && e4 > 1 ? (4 ** e4 - 1) / (3 * 4 ** (e4 - 1)) : 1;
  return Math.ceil(n5 * s5 * a3 * g3);
}
function T(e4) {
  return e4.getNumImages() >= 1 && !e4.isUASTC();
}
function _3(e4) {
  return e4.getFaces() >= 1 && e4.isETC1S();
}
async function h2(t3, n5, r3) {
  t(g) && (g = await c4());
  const s5 = new g.BasisFile(new Uint8Array(r3));
  if (!T(s5))
    return null;
  s5.startTranscoding();
  const i5 = p(t3, n5, s5.getNumLevels(0), s5.getHasAlpha(), s5.getImageWidth(0, 0), s5.getImageHeight(0, 0), (e4, t4) => s5.getImageTranscodedSizeInBytes(0, e4, t4), (e4, t4, n6) => s5.transcodeImage(n6, 0, e4, t4, 0, 0));
  return s5.close(), s5.delete(), i5;
}
async function A(t3, n5, r3) {
  t(g) && (g = await c4());
  const s5 = new g.KTX2File(new Uint8Array(r3));
  if (!_3(s5))
    return null;
  s5.startTranscoding();
  const i5 = p(t3, n5, s5.getLevels(), s5.getHasAlpha(), s5.getWidth(), s5.getHeight(), (e4, t4) => s5.getImageTranscodedSizeInBytes(e4, 0, 0, t4), (e4, t4, n6) => s5.transcodeImage(n6, e4, 0, 0, t4, 0, -1, -1));
  return s5.close(), s5.delete(), i5;
}
function p(e4, t3, o2, g3, l3, c6, u5, m3) {
  const { compressedTextureETC: E5, compressedTextureS3TC: T3 } = e4.capabilities, [_5, h4] = E5 ? g3 ? [_2.ETC2_RGBA, u.COMPRESSED_RGBA8_ETC2_EAC] : [_2.ETC1_RGB, u.COMPRESSED_RGB8_ETC2] : T3 ? g3 ? [_2.BC3_RGBA, u.COMPRESSED_RGBA_S3TC_DXT5_EXT] : [_2.BC1_RGB, u.COMPRESSED_RGB_S3TC_DXT1_EXT] : [_2.RGBA32, P.RGBA], A3 = t3.hasMipmap ? o2 : Math.min(1, o2), p3 = [];
  for (let n5 = 0; n5 < A3; n5++)
    p3.push(new Uint8Array(u5(n5, _5))), m3(n5, _5, p3[n5]);
  const C2 = p3.length > 1, d2 = C2 ? L.LINEAR_MIPMAP_LINEAR : L.LINEAR, R = { ...t3, samplingMode: d2, hasMipmap: C2, internalFormat: h4, width: l3, height: c6 };
  return new E2(e4, R, { type: "compressed", levels: p3 });
}

// node_modules/@arcgis/core/views/3d/webgl-engine/lib/DDSUtil.js
var i4 = s.getLogger("esri.views.3d.webgl-engine.lib.DDSUtil");
var s4 = 542327876;
var l2 = 131072;
var m2 = 4;
function u4(e4) {
  return e4.charCodeAt(0) + (e4.charCodeAt(1) << 8) + (e4.charCodeAt(2) << 16) + (e4.charCodeAt(3) << 24);
}
function c5(e4) {
  return String.fromCharCode(255 & e4, e4 >> 8 & 255, e4 >> 16 & 255, e4 >> 24 & 255);
}
var h3 = u4("DXT1");
var p2 = u4("DXT3");
var d = u4("DXT5");
var g2 = 31;
var f3 = 0;
var C = 1;
var w = 2;
var D2 = 3;
var _4 = 4;
var T2 = 7;
var A2 = 20;
var E4 = 21;
function S(e4, r3, n5) {
  var _a;
  const { textureData: i5, internalFormat: s5, width: l3, height: m3 } = f(M2(n5, (_a = r3.hasMipmap) != null ? _a : false));
  return r3.samplingMode = i5.levels.length > 1 ? L.LINEAR_MIPMAP_LINEAR : L.LINEAR, r3.hasMipmap = i5.levels.length > 1, r3.internalFormat = s5, r3.width = l3, r3.height = m3, new E2(e4, r3, i5);
}
function M2(e4, t3) {
  const o2 = new Int32Array(e4, 0, g2);
  if (o2[f3] !== s4)
    return i4.error("Invalid magic number in DDS header"), null;
  if (!(o2[A2] & m2))
    return i4.error("Unsupported format, must contain a FourCC code"), null;
  const a3 = o2[E4];
  let u5, S2;
  switch (a3) {
    case h3:
      u5 = 8, S2 = u.COMPRESSED_RGB_S3TC_DXT1_EXT;
      break;
    case p2:
      u5 = 16, S2 = u.COMPRESSED_RGBA_S3TC_DXT3_EXT;
      break;
    case d:
      u5 = 16, S2 = u.COMPRESSED_RGBA_S3TC_DXT5_EXT;
      break;
    default:
      return i4.error("Unsupported FourCC code:", c5(a3)), null;
  }
  let M3 = 1, R = o2[_4], b = o2[D2];
  0 == (3 & R) && 0 == (3 & b) || (i4.warn("Rounding up compressed texture size to nearest multiple of 4."), R = R + 3 & -4, b = b + 3 & -4);
  const x2 = R, X2 = b;
  let I, j;
  o2[w] & l2 && false !== t3 && (M3 = Math.max(1, o2[T2])), 1 === M3 || c(R) && c(b) || (i4.warn("Ignoring mipmaps of non power of two sized compressed texture."), M3 = 1);
  let v2 = o2[C] + 4;
  const F = [];
  for (let r3 = 0; r3 < M3; ++r3)
    j = (R + 3 >> 2) * (b + 3 >> 2) * u5, I = new Uint8Array(e4, v2, j), F.push(I), v2 += j, R = Math.max(1, R >> 1), b = Math.max(1, b >> 1);
  return { textureData: { type: "compressed", levels: F }, internalFormat: S2, width: x2, height: X2 };
}

// node_modules/@arcgis/core/views/3d/webgl-engine/lib/Texture.js
var L2 = class extends r2 {
  constructor(t3, e4) {
    super(), this._data = t3, this.type = e3.Texture, this._glTexture = null, this._powerOfTwoStretchInfo = null, this._loadingPromise = null, this._loadingController = null, this.events = new n(), this._passParameters = new i2(), this.params = e4 || {}, this.params.mipmap = false !== this.params.mipmap, this.params.noUnpackFlip = this.params.noUnpackFlip || false, this.params.preMultiplyAlpha = this.params.preMultiplyAlpha || false, this.params.wrap = this.params.wrap || { s: D.REPEAT, t: D.REPEAT }, this.params.powerOfTwoResizeMode = this.params.powerOfTwoResizeMode || c3.STRETCH, this.estimatedTexMemRequired = L2._estimateTexMemRequired(this._data, this.params), this._startPreload();
  }
  _startPreload() {
    const t3 = this._data;
    t(t3) || (t3 instanceof HTMLVideoElement ? this._startPreloadVideoElement(t3) : t3 instanceof HTMLImageElement && this._startPreloadImageElement(t3));
  }
  _startPreloadVideoElement(t3) {
    if (!(V(t3.src) || "auto" === t3.preload && t3.crossOrigin)) {
      t3.preload = "auto", t3.crossOrigin = "anonymous";
      const e4 = !t3.paused;
      if (t3.src = t3.src, e4 && t3.autoplay) {
        const e5 = () => {
          t3.removeEventListener("canplay", e5), t3.play();
        };
        t3.addEventListener("canplay", e5);
      }
    }
  }
  _startPreloadImageElement(t3) {
    X(t3.src) || V(t3.src) || t3.crossOrigin || (t3.crossOrigin = "anonymous", t3.src = t3.src);
  }
  static _getDataDimensions(t3) {
    return t3 instanceof HTMLVideoElement ? { width: t3.videoWidth, height: t3.videoHeight } : t3;
  }
  static _estimateTexMemRequired(t3, e4) {
    if (t(t3))
      return 0;
    if (o(t3) || e(t3))
      return e4.encoding === L2.KTX2_ENCODING ? m(t3, e4.mipmap) : e4.encoding === L2.BASIS_ENCODING ? u3(t3, e4.mipmap) : t3.byteLength;
    const { width: r3, height: i5 } = t3 instanceof Image || t3 instanceof ImageData || t3 instanceof HTMLCanvasElement || t3 instanceof HTMLVideoElement ? L2._getDataDimensions(t3) : e4;
    return (e4.mipmap ? 4 / 3 : 1) * r3 * i5 * (e4.components || 4) || 0;
  }
  dispose() {
    this._data = void 0;
  }
  get width() {
    return this.params.width;
  }
  get height() {
    return this.params.height;
  }
  _createDescriptor(t3) {
    var _a;
    return { target: M.TEXTURE_2D, pixelFormat: P.RGBA, dataType: G.UNSIGNED_BYTE, wrapMode: this.params.wrap, flipped: !this.params.noUnpackFlip, samplingMode: this.params.mipmap ? L.LINEAR_MIPMAP_LINEAR : L.LINEAR, hasMipmap: this.params.mipmap, preMultiplyAlpha: this.params.preMultiplyAlpha, maxAnisotropy: (_a = this.params.maxAnisotropy) != null ? _a : this.params.mipmap ? t3.parameters.maxMaxAnisotropy : 1 };
  }
  get glTexture() {
    return this._glTexture;
  }
  load(t3, e4) {
    if (r(this._glTexture))
      return this._glTexture;
    if (r(this._loadingPromise))
      return this._loadingPromise;
    const r3 = this._data;
    return t(r3) ? (this._glTexture = new E2(t3, this._createDescriptor(t3), null), this._glTexture) : "string" == typeof r3 ? this._loadFromURL(t3, e4, r3) : r3 instanceof Image ? this._loadFromImageElement(t3, e4, r3) : r3 instanceof HTMLVideoElement ? this._loadFromVideoElement(t3, e4, r3) : r3 instanceof ImageData || r3 instanceof HTMLCanvasElement ? this._loadFromImage(t3, r3, e4) : (o(r3) || e(r3)) && this.params.encoding === L2.DDS_ENCODING ? (this._data = void 0, this._loadFromDDSData(t3, r3)) : (o(r3) || e(r3)) && this.params.encoding === L2.KTX2_ENCODING ? (this._data = void 0, this._loadFromKTX2(t3, r3)) : (o(r3) || e(r3)) && this.params.encoding === L2.BASIS_ENCODING ? (this._data = void 0, this._loadFromBasis(t3, r3)) : e(r3) ? this._loadFromPixelData(t3, r3) : o(r3) ? this._loadFromPixelData(t3, new Uint8Array(r3)) : null;
  }
  get requiresFrameUpdates() {
    return this._data instanceof HTMLVideoElement;
  }
  frameUpdate(t3, e4, r3) {
    if (!(this._data instanceof HTMLVideoElement) || t(this._glTexture))
      return r3;
    if (this._data.readyState < G2.HAVE_CURRENT_DATA || r3 === this._data.currentTime)
      return r3;
    if (r(this._powerOfTwoStretchInfo)) {
      const { framebuffer: r4, vao: i5, sourceTexture: s5 } = this._powerOfTwoStretchInfo;
      s5.setData(this._data), this._drawStretchedTexture(t3, e4, r4, i5, s5, this._glTexture);
    } else {
      const { videoWidth: t4, videoHeight: e5 } = this._data, { width: r4, height: i5 } = this._glTexture.descriptor;
      t4 !== r4 || e5 !== i5 ? this._glTexture.updateData(0, 0, 0, Math.min(t4, r4), Math.min(e5, i5), this._data) : this._glTexture.setData(this._data);
    }
    return this._glTexture.descriptor.hasMipmap && this._glTexture.generateMipmap(), this.params.updateCallback && this.params.updateCallback(), this._data.currentTime;
  }
  _loadFromDDSData(t3, e4) {
    return this._glTexture = S(t3, this._createDescriptor(t3), e4), this._glTexture;
  }
  _loadFromKTX2(t3, e4) {
    return this._loadAsync(() => A(t3, this._createDescriptor(t3), e4).then((t4) => (this._glTexture = t4, t4)));
  }
  _loadFromBasis(t3, e4) {
    return this._loadAsync(() => h2(t3, this._createDescriptor(t3), e4).then((t4) => (this._glTexture = t4, t4)));
  }
  _loadFromPixelData(t3, e4) {
    e2(this.params.width > 0 && this.params.height > 0);
    const r3 = this._createDescriptor(t3);
    return r3.pixelFormat = 1 === this.params.components ? P.LUMINANCE : 3 === this.params.components ? P.RGB : P.RGBA, r3.width = this.params.width, r3.height = this.params.height, this._glTexture = new E2(t3, r3, e4), this._glTexture;
  }
  _loadFromURL(t3, e4, r3) {
    return this._loadAsync(async (i5) => {
      const s5 = await t2(r3, { signal: i5 });
      return f2(i5), this._loadFromImage(t3, s5, e4);
    });
  }
  _loadFromImageElement(t3, e4, r3) {
    return r3.complete ? this._loadFromImage(t3, r3, e4) : this._loadAsync(async (i5) => {
      const s5 = await c2(r3, r3.src, false, i5);
      return f2(i5), this._loadFromImage(t3, s5, e4);
    });
  }
  _loadFromVideoElement(t3, e4, r3) {
    return r3.readyState >= G2.HAVE_CURRENT_DATA ? this._loadFromImage(t3, r3, e4) : this._loadFromVideoElementAsync(t3, e4, r3);
  }
  _loadFromVideoElementAsync(t3, r3, i5) {
    return this._loadAsync((s5) => new Promise((a3, o2) => {
      const m3 = () => {
        i5.removeEventListener("loadeddata", p3), i5.removeEventListener("error", d2), h(_5);
      }, p3 = () => {
        i5.readyState >= G2.HAVE_CURRENT_DATA && (m3(), a3(this._loadFromImage(t3, i5, r3)));
      }, d2 = (t4) => {
        m3(), o2(t4 || new s2("Failed to load video"));
      };
      i5.addEventListener("loadeddata", p3), i5.addEventListener("error", d2);
      const _5 = v(s5, () => d2(a()));
    }));
  }
  _loadFromImage(t3, e4, r3) {
    const s5 = L2._getDataDimensions(e4);
    this.params.width = s5.width, this.params.height = s5.height;
    const a3 = this._createDescriptor(t3);
    return a3.pixelFormat = 3 === this.params.components ? P.RGB : P.RGBA, !this._requiresPowerOfTwo(t3, a3) || c(s5.width) && c(s5.height) ? (a3.width = s5.width, a3.height = s5.height, this._glTexture = new E2(t3, a3, e4), this._glTexture) : (this._glTexture = this._makePowerOfTwoTexture(t3, e4, s5, a3, r3), this._glTexture);
  }
  _loadAsync(t3) {
    const e4 = new AbortController();
    this._loadingController = e4;
    const r3 = t3(e4.signal);
    this._loadingPromise = r3;
    const i5 = () => {
      this._loadingController === e4 && (this._loadingController = null), this._loadingPromise === r3 && (this._loadingPromise = null);
    };
    return r3.then(i5, i5), r3;
  }
  _requiresPowerOfTwo(t3, e4) {
    const r3 = D.CLAMP_TO_EDGE, i5 = "number" == typeof e4.wrapMode ? e4.wrapMode === r3 : e4.wrapMode.s === r3 && e4.wrapMode.t === r3;
    return !n3(t3.gl) && (e4.hasMipmap || !i5);
  }
  _makePowerOfTwoTexture(e4, r3, i5, a3, o2) {
    const { width: n5, height: m3 } = i5, h4 = i(n5), l3 = i(m3);
    let p3;
    switch (a3.width = h4, a3.height = l3, this.params.powerOfTwoResizeMode) {
      case c3.PAD:
        a3.textureCoordinateScaleFactor = [n5 / h4, m3 / l3], p3 = new E2(e4, a3), p3.updateData(0, 0, 0, n5, m3, r3);
        break;
      case c3.STRETCH:
      case null:
      case void 0:
        p3 = this._stretchToPowerOfTwo(e4, r3, a3, o2());
        break;
      default:
        n2(this.params.powerOfTwoResizeMode);
    }
    return a3.hasMipmap && p3.generateMipmap(), p3;
  }
  _stretchToPowerOfTwo(t3, e4, r3, i5) {
    const s5 = new E2(t3, r3), a3 = new x(t3, { colorTarget: Y.TEXTURE, depthStencilTarget: V2.NONE }, s5), o2 = new E2(t3, { target: M.TEXTURE_2D, pixelFormat: r3.pixelFormat, dataType: G.UNSIGNED_BYTE, wrapMode: D.CLAMP_TO_EDGE, samplingMode: L.LINEAR, flipped: !!r3.flipped, maxAnisotropy: 8, preMultiplyAlpha: r3.preMultiplyAlpha }, e4), n5 = u2(t3), m3 = t3.getBoundFramebufferObject();
    return this._drawStretchedTexture(t3, i5, a3, n5, o2, s5), this.requiresFrameUpdates ? this._powerOfTwoStretchInfo = { vao: n5, sourceTexture: o2, framebuffer: a3 } : (n5.dispose(true), o2.dispose(), a3.detachColorTexture(), a3.dispose()), t3.bindFramebuffer(m3), s5;
  }
  _drawStretchedTexture(t3, e4, r3, i5, s5, a3) {
    this._passParameters.texture = s5, t3.bindFramebuffer(r3);
    const o2 = t3.getViewport();
    t3.setViewport(0, 0, a3.descriptor.width, a3.descriptor.height), t3.bindTechnique(e4, this._passParameters, null), t3.bindVAO(i5), t3.drawArrays(E.TRIANGLE_STRIP, 0, n4(i5, "geometry")), t3.bindFramebuffer(null), t3.setViewport(o2.x, o2.y, o2.width, o2.height), this._passParameters.texture = null;
  }
  unload() {
    if (r(this._powerOfTwoStretchInfo)) {
      const { framebuffer: t3, vao: e4, sourceTexture: r3 } = this._powerOfTwoStretchInfo;
      e4.dispose(true), r3.dispose(), t3.dispose(), this._glTexture = null, this._powerOfTwoStretchInfo = null;
    }
    if (r(this._glTexture) && (this._glTexture.dispose(), this._glTexture = null), r(this._loadingController)) {
      const t3 = this._loadingController;
      this._loadingController = null, this._loadingPromise = null, t3.abort();
    }
    this.events.emit("unloaded");
  }
};
var G2;
L2.DDS_ENCODING = "image/vnd-ms.dds", L2.KTX2_ENCODING = "image/ktx2", L2.BASIS_ENCODING = "image/x.basis", function(t3) {
  t3[t3.HAVE_NOTHING = 0] = "HAVE_NOTHING", t3[t3.HAVE_METADATA = 1] = "HAVE_METADATA", t3[t3.HAVE_CURRENT_DATA = 2] = "HAVE_CURRENT_DATA", t3[t3.HAVE_FUTURE_DATA = 3] = "HAVE_FUTURE_DATA", t3[t3.HAVE_ENOUGH_DATA = 4] = "HAVE_ENOUGH_DATA";
}(G2 || (G2 = {}));

export {
  L2 as L
};
//# sourceMappingURL=chunk-IMFUUJSK.js.map
